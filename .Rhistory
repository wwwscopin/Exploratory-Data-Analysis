dat = read.csv("gaData.csv")
training = dat[year(dat$date)  2011,]
tstrain = ts(training$visitsTumblr)
training = dat[year(dat$date)==2011,]
str(data)
str(dat)
str(dat)
training = dat[year(as.Date(dat$date))==2011,]
training = dat[as.POSIXlt((as.Date(dat$date)))$year==2011,]
tstrain = ts(training$visitsTumblr)
str(training)
tstrain = ts(training$visitsTumblr)
tstrain = ts(training$visitsTumblr,frequency=1)
head(training)
dat = read.csv("gaData.csv")
head(dat)
training = dat[as.POSIXlt((as.Date(dat$date)))$year==2011,]
head(training)
training = dat[as.POSIXlt((as.Date(dat$date)))$year=='2011',]
head(training)
training = dat[as.POSIXlt(s.Date(dat$date))$year=='2011',]
training = dat[as.POSIXlt(as.Date(dat$date))$year=='2011',]
head(training)
as.Date(dat$date)
as.POSIXlt(as.Date(dat$date))
as.POSIXlt(as.Date(dat$date))$year
as.POSIXlt(as.Date(dat$date))
install.packages("lubridate")
training = dat[year(dat$date)=='2011',]
require(lubridate)
training = dat[year(dat$date)=='2011',]
head(training)
training = dat[year(dat$date)==2011,]
head(training)
tstrain = ts(training$visitsTumblr)
head(training)
tstrain
require(forecast)
install.packages("forecast")
require(forecast)
testing = dat[-year(dat$date)==2011,]
tstest = ts(testing$visitsTumblr)
str(testing)
testing = dat[year(dat$date)!=2011,]
str(testing)
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
wbh<-predict(fit, newdata=tstest)
wbh
str(testing)
tstest
wbh<-predict(fit, newdata=tstest)
wbh
dim(wbh)
length(wbh)
str(testing)
9/235
1-9/235
install.packages("AppliedPredictiveModeling")
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
set.seed(233)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
wbh
tstest
testing
require(lubridate)
require(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)!=2011,]
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
testing
tstest
testing
tstest
wbh
fit
?bats
?predict
wbh<-forecast(fit, newdata=tstest)
bh
wbh
plot(forecast(fit, newdata=tstest))
testing
tstest
wbh<-forecast(fit, newdata=tstest)
wbh
fit2 <- ets(tstest, model=fit)
wbh<-forecast(fit, newdata=tstest)
wbh
tstest
tstest
wbh
names(wbh)
str(names)
str(wbh)
wbh$fitted.values
wbh
str(wbh)
head(wbh)
wbh<-predict(fit, newdata=tstest)
wbh$fitted.values
str(wbh)
wbh
sum(tstest<774.1413 & tstest>-333.3223)/length(tstest)
set.seed(3523)
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
set.seed(233)
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
str(training)
m = lars(training[,-9],training$CompressiveStrength,type = "lasso", normalize = FALSE, intercept = TRUE)
test<-enet(train[,-9], train[,9], 0)
install.packages("elasticnet")
require(elasticnet)
require(elasticnet)
test<-enet(train[,-9], train[,9], 0)
plot.enet(fit$finalModel, xvar="penalty", use.color=T)
test<-enet(training[,-9], training[,9], 0)
str(training)
training[,9]
training[,-9]
training[,-9]
test<-enet(training[,-9], training[,9], 0)
test<-enet(training[,-9], training[,9], lambda=0)
str(training)
test<-enet(training[,-9], training$CompressiveStrength, lambda=0)
test<-enet(as.Matrix(training[,-9]), training$CompressiveStrength, lambda=0)
test<-enet(as.matrix(training[,-9]), training$CompressiveStrength, lambda=0)
plot.enet(test$finalModel, xvar="penalty", use.color=T)
require(elasticnet)
test<-enet(as.matrix(training[,-9]), training$CompressiveStrength, lambda=0)
plot.enet(test$finalModel, xvar="penalty", use.color=T)
test
str(test)
test
test<-enet(as.matrix(training[,-9]), training$CompressiveStrength, lambda=0)
plot.enet(test$finalModel, xvar="penalty", use.color=T)
plot.enet(test, xvar="penalty", use.color=T)
plot.enet(test, xvar="penalty", use.color=T)
set.seed(3523)
library(AppliedPredictiveModeling)
library(caret)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
str(training)
set.seed(233)
require(elasticnet)
test<-enet(as.matrix(training[,-9]), training$CompressiveStrength, lambda=0)
plot.enet(test, xvar="penalty", use.color=T)
library(ElemStatLearn)
data(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
str(vowel.train)
set.seed(33833)
#library(randomForest)
library(caret)
mf1<-train(y~., data=vowel.train, method="rf")
pred_RF<-predict(mf1,vowel.test)
mf2<-train(y~., data=vowel.train, method="gbm")
pred_GBM<-predict(mf2,vowel.test)
accuracy_GBM = (vowel.test$y == pred_GBM);
accuracy_RF = (vowel.test$y == pred_RF);
accuracy = (vowel.test$y == pred_RF & vowel.test$y == pred_GBM);
accuracy_test = (pred_RF == pred_GBM);
length(accuracy_GBM[accuracy_GBM == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]);
length(accuracy[accuracy == TRUE]);
length(accuracy_test[accuracy_test == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]) / length(accuracy_RF);
length(accuracy_GBM[accuracy_GBM == TRUE]) / length(accuracy_GBM);
length(accuracy[accuracy == TRUE]) / length(accuracy);
length(accuracy[accuracy == TRUE]) / length(accuracy_test[accuracy_test == TRUE]);
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
str(vowel.train)
set.seed(33833)
#library(randomForest)
library(caret)
mf1<-train(y~., data=vowel.train, method="rf")
library(ElemStatLearn)
data(vowel.train)
vowel.train$y<-as.factor(vowel.train$y)
data(vowel.test)
vowel.test$y<-as.factor(vowel.test$y)
str(vowel.train)
set.seed(33833)
#library(randomForest)
library(caret)
mf1<-train(y~., data=vowel.train, method="rf")
pred_RF<-predict(mf1,vowel.test)
mf2<-train(y~., data=vowel.train, method="gbm")
accuracy_GBM = (vowel.test$y == pred_GBM);
accuracy_RF = (vowel.test$y == pred_RF);
accuracy = (vowel.test$y == pred_RF & vowel.test$y == pred_GBM);
accuracy_test = (pred_RF == pred_GBM);
length(accuracy_GBM[accuracy_GBM == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]);
length(accuracy[accuracy == TRUE]);
length(accuracy_test[accuracy_test == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]) / length(accuracy_RF);
length(accuracy_GBM[accuracy_GBM == TRUE]) / length(accuracy_GBM);
length(accuracy[accuracy == TRUE]) / length(accuracy);
length(accuracy[accuracy == TRUE]) / length(accuracy_test[accuracy_test == TRUE]);
pred_GBM<-predict(mf2,vowel.test)
accuracy_GBM = (vowel.test$y == pred_GBM);
accuracy_RF = (vowel.test$y == pred_RF);
accuracy = (vowel.test$y == pred_RF & vowel.test$y == pred_GBM);
accuracy_test = (pred_RF == pred_GBM);
length(accuracy_GBM[accuracy_GBM == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]);
length(accuracy[accuracy == TRUE]);
length(accuracy_test[accuracy_test == TRUE]);
length(accuracy_RF[accuracy_RF == TRUE]) / length(accuracy_RF);
length(accuracy_GBM[accuracy_GBM == TRUE]) / length(accuracy_GBM);
length(accuracy[accuracy == TRUE]) / length(accuracy);
length(accuracy[accuracy == TRUE]) / length(accuracy_test[accuracy_test == TRUE]);
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
mf1<-train(diagnosis~., data=training, method="rf")
mf2<-train(diagnosis~., data=training, method="gbm")
mf3<-train(diagnosis~., data=training, method="lda")
pred1<-predict(mf1,testing)
pred2<-predict(mf2,testing)
pred3<-predict(mf3,testing)
accuracy1 = (testing$diagnosis == pred1);
length(accuracy1[accuracy1 == TRUE])/length(accuracy1)
accuracy2 = (testing$diagnosis == pred2);
length(accuracy2[accuracy2 == TRUE])/length(accuracy2)
accuracy3 = (testing$diagnosis == pred3);
length(accuracy3[accuracy3 == TRUE])/length(accuracy3)
cpred<-data.frame(pred1, pred2, pred3, diagnosis=testing$diagnosis)
combfit<-train(diagnosis~., method="rf", data=cpred)
combpred<-predict(combfit, cpred)
accuracy = (testing$diagnosis == combpred);
length(accuracy[accuracy == TRUE])/length(accuracy)
#Q4
require(lubridate)
require(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)!=2011,]
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
wbh<-predict(fit, newdata=tstest)
wbh$fitted.values
sum(tstest<774.1413 & tstest>-333.3223)/length(tstest)
require(lubridate)
require(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)!=2011,]
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
wbh<-predict(fit, newdata=tstest)
wbh
sum(tstest<774.1413 & tstest>-333.3223)/length(tstest)
require(lubridate)
require(forecast)
dat = read.csv("gaData.csv")
training = dat[year(dat$date)==2011,]
tstrain = ts(training$visitsTumblr)
testing = dat[year(dat$date)!=2011,]
tstest = ts(testing$visitsTumblr)
fit <- bats(tstrain, use.parallel=FALSE)
wbh<-predict(fit, newdata=tstest)
wbh
sum(tstest<774.1413 & tstest>-333.3223)/length(tstest)
10/length(tstest)
1-10/length(tstest)
